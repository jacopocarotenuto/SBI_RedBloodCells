{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- manca da aggiungere il fit di tucci\n",
    "- manca da vedere se il formato di compute summary gli piace o no\n",
    "- manca il run per debagguare eventuali errori "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported libraries and statistical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"./../..\")\n",
    "\n",
    "from numba import jit\n",
    "from numba.types import bool_, int_\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from InternalLibrary.StatisticalFunctions import stat_corr_single, stat_s_redx\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import moment\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sbi import analysis as analysis\n",
    "from sbi import utils as utils\n",
    "from sbi.inference import SNPE, simulate_for_sbi, infer\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")\n",
    "import torch\n",
    "import statistics\n",
    "\n",
    "from InternalLibrary.StatisticalFunctions import *\n",
    "from InternalLibrary.SimulatorPackage import Simulator_noGPU\n",
    "from pathos.multiprocessing import ProcessingPool as ProcessPool\n",
    "import pathos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class of the simulator\n",
    "class ParallelSimulator():\n",
    "    def __init__(self, dt, DeltaT, TotalT, prior_lims, transient_time = 0, batch_size = 50, multi_round_mode = False, prior = None) -> None:\n",
    "        self.sim_param = {'dt': dt, 'DeltaT': DeltaT, 'TotalT': TotalT, 'transient_time': transient_time}\n",
    "        self.pool = ProcessPool(nodes=pathos.helpers.cpu_count())\n",
    "        self.batch_size = batch_size\n",
    "        self.prior_limits = prior_lims\n",
    "        _ = self._dummy_run()\n",
    "        self.multi_round_mode = multi_round_mode\n",
    "        self.prior = prior\n",
    "    \n",
    "    def _dummy_run(self):\n",
    "        Simulator_noGPU(dt = 1, DeltaT=1, TotalT = 2, theta = np.zeros(5).reshape(5,1,1), transient_time = 0)\n",
    "    \n",
    "    def _run_simulator(self, theta):\n",
    "        return Simulator_noGPU(theta = theta, **self.sim_param)\n",
    "    \n",
    "    def _get_theta(self):\n",
    "        if self.multi_round_mode:\n",
    "            return self.prior.sample((self.batch_size,1)).T.reshape(5,self.batch_size,1).numpy()\n",
    "        return get_theta_from_prior(self.prior_limits, self.batch_size)[0]\n",
    "    \n",
    "    def run(self,N):\n",
    "        thetas = [self._get_theta() for _ in range(N)]\n",
    "        s = self.pool.map(self._run_simulator, thetas)\n",
    "        x = s[0][0]\n",
    "        y = s[0][1]\n",
    "        f = s[0][2]\n",
    "        for i in np.arange(1,len(s)):\n",
    "            x = np.concatenate([x, s[i][0]])\n",
    "            y = np.concatenate([y, s[i][1]])\n",
    "            f = np.concatenate([f, s[i][2]])\n",
    "        t = thetas[0]\n",
    "        for i in np.arange(1,len(thetas)):\n",
    "            t = np.concatenate([t, thetas[i]],axis = 1)\n",
    "        return x, y, f, t\n",
    "    \n",
    "    def same_theta_test(self,N,theta):\n",
    "        thetas = [theta for _ in range(N)]\n",
    "        s = self.pool.map(self._run_simulator, thetas)\n",
    "        x = s[0][0]\n",
    "        y = s[0][1]\n",
    "        f = s[0][2]\n",
    "        for i in np.arange(1,len(s)):\n",
    "            x = np.concatenate([x, s[i][0]])\n",
    "            y = np.concatenate([y, s[i][1]])\n",
    "            f = np.concatenate([f, s[i][2]])\n",
    "        return x, y, f\n",
    "    \n",
    "    \n",
    "    \n",
    "def prior_from_lims(prior_lims):\n",
    "    NumberOfParameters = len(prior_lims)\n",
    "    BoxLimits = np.zeros((2, NumberOfParameters))\n",
    "    i = 0\n",
    "    for item in prior_lims.items():\n",
    "        BoxLimits[0, i] = item[1][0]\n",
    "        BoxLimits[1, i] = item[1][1]\n",
    "        i +=1\n",
    "    BoxLimits = torch.tensor(BoxLimits)\n",
    "    prior = utils.BoxUniform(low=BoxLimits[0], high=BoxLimits[1])\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions for the fit \n",
    "def stat_fit_corr(single_corr, DeltaT):\n",
    "    \"\"\"\n",
    "    Fit the correlation function with a sum of 3 exponentials\n",
    "    \"\"\"\n",
    "    t_cxx = np.linspace(0., (len(single_corr)+1)*DeltaT, (len(single_corr)+1))[1:]\n",
    "    \n",
    "    def cxx_exp3(t, a1, a2, a3, b1, b2, b3):\n",
    "        return a1*np.exp(-b1*t) + a2*np.exp(-b2*t) + a3*np.exp(-b3*t)\n",
    "    \n",
    "    try: \n",
    "        popt, pcov = curve_fit(cxx_exp3, t_cxx, single_corr, p0=[1e2, 1e2, 1e2, 10, 10, 10], maxfev=5000)\n",
    "    except:\n",
    "        return np.zeros(6)\n",
    "\n",
    "    return popt, cxx_exp3(t_cxx, *popt)\n",
    "\n",
    "def stat_fit_s_redx(single_s_redx, DeltaT, mode=\"exp\"):\n",
    "    \"\"\"\n",
    "    Fit the s_redx function\n",
    "    \"\"\"\n",
    "    assert mode in [\"exp\", \"simple\"], \"Mode not recognized\"\n",
    "\n",
    "    t_cxx = np.linspace(0., (len(single_s_redx)+1)*DeltaT, (len(single_s_redx)+1))[1:]\n",
    "    \n",
    "    def s_redx_simple(t, a, tau):\n",
    "        return(1 + a*t/(1+t/tau))\n",
    "\n",
    "    def s_redx_exp(t, a1, a2, b1, b2, b3, c):\n",
    "        a3 = 1 - a1 - a2 \n",
    "        sum_exp = a1*np.exp(-b1*t) + (a2)*np.exp(-(b1+b2)*t) + (a3)*np.exp(-(b1+b2+b3)*t)\n",
    "        sum = a1*b1 + (a2)*(b1+b2) + (a3)*(b1+b2+b3)\n",
    "        tau = 1/sum\n",
    "        return(1 + c - (c*tau/t)*(1-sum_exp))\n",
    "    \n",
    "    if mode == \"exp\":\n",
    "        try: \n",
    "            popt, pcov = curve_fit(s_redx_exp, t_cxx, single_s_redx, p0=[1, 10, 10, 0.1, 0.01, 10],\n",
    "                          bounds=([0, 0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf]), maxfev=5000)\n",
    "        except:\n",
    "            return np.zeros(6)\n",
    "        return popt, s_redx_exp(t_cxx, *popt)\n",
    "\n",
    "    if mode == \"simple\":\n",
    "        try:\n",
    "            popt, pcov = curve_fit(s_redx_simple, t_cxx, single_s_redx, p0=[1e3, 1e-2],\n",
    "                          bounds=([0, 0], [np.inf, np.inf]), maxfev=5000)\n",
    "        except:\n",
    "            return np.zeros(6)\n",
    "        return popt, s_redx_simple(t_cxx, *popt)\n",
    "        \n",
    "\n",
    "def select_summary_statistics(summary_statistics, selected_statistics, DeltaT,\n",
    "                              z_score=False, cl_lin=-1, cl_log=-1, fit_cxx=False, fit_s_redx=False):\n",
    "    selected_statistics = selected_statistics.copy()\n",
    "    \n",
    "    # Check that the selected statistics are in the summary statistics\n",
    "    assert set(selected_statistics).issubset(set(summary_statistics.keys()))\n",
    "    \"The selected statistics are not in the summary statistics\"\n",
    "\n",
    "    # Checks on postprocessing\n",
    "    assert cl_log < 0 or cl_lin < 0, \"You cannot subsample bot 'lin' and 'log' at the same time\"\n",
    "    if cl_lin > 0 or cl_log > 0: assert (fit_cxx == False) and (fit_s_redx == False), \"You cannot subsample and fit at the same time\"\n",
    "    \n",
    "    # Post-subselection of Cxx and s_redx\n",
    "    if cl_lin > 0:\n",
    "        idx_clean_corr = np.linspace(0, len(summary_statistics[\"Cxx\"])-1, cl_lin, dtype=np.int32)\n",
    "        if \"Cxx\" in selected_statistics:\n",
    "            summary_statistics[\"Cxx\"] = summary_statistics[\"Cxx\"][idx_clean_corr]\n",
    "        if \"s_redx\" in selected_statistics:\n",
    "            summary_statistics[\"s_redx\"] = summary_statistics[\"s_redx\"][idx_clean_corr]\n",
    "        if \"s_red1\" in selected_statistics:\n",
    "            summary_statistics[\"s_red1\"] = summary_statistics[\"s_red1\"][idx_clean_corr]\n",
    "        if \"s_red2\" in selected_statistics:\n",
    "            summary_statistics[\"s_red2\"] = summary_statistics[\"s_red2\"][idx_clean_corr]\n",
    "\n",
    "    if cl_log > 0:\n",
    "        idx_clean_corr = np.logspace(0, np.log10(len(summary_statistics[\"Cxx\"])-1), cl_log, dtype=np.int32)\n",
    "        if \"Cxx\" in selected_statistics:\n",
    "            summary_statistics[\"Cxx\"] = summary_statistics[\"Cxx\"][idx_clean_corr]\n",
    "        if \"s_redx\" in selected_statistics:\n",
    "            summary_statistics[\"s_redx\"] = summary_statistics[\"s_redx\"][idx_clean_corr]\n",
    "        if \"s_red1\" in selected_statistics:\n",
    "            summary_statistics[\"s_red1\"] = summary_statistics[\"s_red1\"][idx_clean_corr]\n",
    "        if \"s_red2\" in selected_statistics:\n",
    "            summary_statistics[\"s_red2\"] = summary_statistics[\"s_red2\"][idx_clean_corr]\n",
    "\n",
    "    # Fit Cxx and s_redx and use the paramaters as summary statistics\n",
    "    if fit_cxx and \"Cxx\" in selected_statistics:\n",
    "        summary_statistics[\"Cxx\"] = stat_fit_corr(summary_statistics[\"Cxx\"], DeltaT)[0]\n",
    "        if (summary_statistics[\"Cxx\"] == np.zeros(6)).all(): return None\n",
    "\n",
    "    if fit_s_redx and \"s_redx\" in selected_statistics:\n",
    "        summary_statistics[\"s_redx\"] = stat_fit_s_redx(summary_statistics[\"s_redx\"], DeltaT, mode=fit_s_redx)[0]\n",
    "        if (summary_statistics[\"s_redx\"] == np.zeros(6)).all(): return None\n",
    "        \n",
    "    # Check if theta is selected for testing reasons\n",
    "    theta_selected = False\n",
    "    if \"theta\" in selected_statistics:\n",
    "        theta_selected = True\n",
    "        selected_statistics.remove(\"theta\")\n",
    "\n",
    "    # Get the selected summary statistics in a torch tensor\n",
    "    if z_score:\n",
    "        list_of_statistics = [torch.tensor(zscore(summary_statistics[i])) for i in selected_statistics]\n",
    "    else:   \n",
    "        list_of_statistics = [torch.tensor(summary_statistics[i]) for i in selected_statistics]\n",
    "    selected_summary_statistics = torch.cat(list_of_statistics, dim=0)\n",
    "    selected_summary_statistics = torch.unsqueeze(selected_summary_statistics, 0)\n",
    "\n",
    "    # Add theta to the summary statistics if selected\n",
    "    if theta_selected:\n",
    "        theta = torch.tensor(summary_statistics[\"theta\"])\n",
    "        selected_summary_statistics = torch.cat((selected_summary_statistics, theta.T), dim=1)\n",
    "\n",
    "    # Convert the summary statistics to float32 (required for sbi)\n",
    "    selected_summary_statistics = selected_summary_statistics.to(torch.float32)\n",
    "    return selected_summary_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the summary statistics and the fit of them\n",
    "def Computesummary(multiple_raw_x_traces,TotalT,transient = 0.5,DeltaT = 1/25_000, function = None):\n",
    "    t = np.linspace(transient, TotalT, multiple_raw_x_traces[0].shape[0])\n",
    "    autocorr = stat_corr_single(multiple_raw_x_traces[0,:], 1) .reshape(1,-1)\n",
    "    n_sim = multiple_raw_x_traces.shape[0]\n",
    "    if n_sim != 1:\n",
    "        for i in np.arange(1,n_sim):\n",
    "            autocorr = np.vstack((autocorr, stat_corr_single(multiple_raw_x_traces[i,:], DeltaT)))\n",
    "    \n",
    "    t_corr = TotalT/10\n",
    "    _,_,RSVP = stat_s_redx(autocorr[0], t_corr, t)\n",
    "    if n_sim != 1:\n",
    "        for i in np.arange(1,n_sim):\n",
    "            _,_,RSVP_ = stat_s_redx(autocorr[i], t_corr, t)\n",
    "            RSVP = np.vstack((RSVP, RSVP_))\n",
    "        \n",
    "    \n",
    "    ### insert the function for tucci's fit here ###\n",
    "    \n",
    "    #fit the summary staristics\n",
    "    summary_stats = {'RSVP': RSVP, 'autocorr': autocorr}\n",
    "    fitted_summary_stats = select_summary_statistics(summary_statistics=summary_stats, selected_statistics=[\"RSVP\", 'autocorr'], DeltaT=DeltaT, z_score=False, cl_lin=-1, cl_log=5, fit_cxx=True, fit_s_redx=True)\n",
    "    \n",
    "    return fitted_summary_stats, summary_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Parameters\n",
    "dt = 1e-6\n",
    "DeltaT = 1/25_000\n",
    "TotalT = 10.\n",
    "transient = 0.5\n",
    "prior_limits = {\n",
    "    \"mu_y\": [1e4, 140e4],\n",
    "    \"k_y\": [1.5e-2, 30e-2],\n",
    "    \"k_int\": [1e-3, 6e-3],\n",
    "    \"tau\": [2e-2, 20e-2],\n",
    "    \"eps\": [0.5, 6],\n",
    "}\n",
    "\n",
    "batch_size = 200\n",
    "N = pathos.helpers.cpu_count()\n",
    "TotalSim = batch_size * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiRoundPipeline(dt,DeltaT,TotalT,prior_lims,transient,batch_size,N,n_rounds):\n",
    "    Simulator = ParallelSimulator(dt, DeltaT, TotalT, prior_lims, transient_time = transient,batch_size = 1)\n",
    "    x, y, f, thetas_exp = Simulator.run(1)\n",
    "    summmary_fit_exp,_ = Computesummary(x, TotalT)\n",
    "    \n",
    "    NumberOfParameters = len(prior_limits)\n",
    "    BoxLimits = np.zeros((2, NumberOfParameters))\n",
    "    i = 0\n",
    "    for item in prior_limits.items():\n",
    "        BoxLimits[0, i] = item[1][0]\n",
    "        BoxLimits[1, i] = item[1][1]\n",
    "        i +=1\n",
    "    BoxLimits = torch.tensor(BoxLimits)\n",
    "    prior = utils.BoxUniform(low=BoxLimits[0], high=BoxLimits[1])\n",
    "    prior, _, _ = process_prior(prior)\n",
    "    infer = SNPE(prior=prior)\n",
    "    proposal = prior\n",
    "    posteriors = []\n",
    "    for _ in np.arange(n_rounds):\n",
    "        print(f\"\\nRound: {_+1} / {n_rounds}\")\n",
    "        Simulator = ParallelSimulator(dt, DeltaT, TotalT, prior_lims, transient_time = transient,batch_size = batch_size, multi_round_mode=True, prior = proposal)\n",
    "        x, y, f, thetas = Simulator.run(N)\n",
    "        summmary_fit = Computesummary(x, TotalT)\n",
    "        summmary_fit = torch.tensor(summmary_fit).float()\n",
    "        theta = torch.tensor(thetas).float().T.reshape(N*batch_size,5)\n",
    "        density_estimator = infer.append_simulations(theta, summmary_fit, proposal = proposal).train()\n",
    "        posterior = infer.build_posterior(density_estimator)\n",
    "        posterior = posterior.set_default_x(summmary_fit_exp)\n",
    "        posteriors.append(posterior)\n",
    "        proposal = posterior\n",
    "    return posteriors, thetas_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, thetas_exp = MultiRoundPipeline(dt,DeltaT,TotalT,prior_limits,transient,batch_size,N,2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_posterior = pos[-1]\n",
    "samples = last_posterior.sample((10000,))\n",
    "fig, ax = analysis.pairplot(samples, figsize=(10, 6), points=thetas_exp.reshape(5,));"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
